---
title: 'The classic XOR classification problem using Keras'
date: 2018-04-11
permalink: /posts/2018/04/xor/
comments: true
tags:
  - Neural Network
  - Keras
  - Classification
  - XOR
---

https://www.quora.com/How-do-I-add-hidden-layers-to-a-neural-network-and-how-many-hidden-units-in-each-layer

 3-layer network can classify any arbitrary shape in n dimensions

2-layer network can classify points inside any n arbitrary lines (n hidden units plus an AND function).
i.e. Can classify:

    any regular polygon
    any convex polygon
    any convex set to any level of granularity required (just add more lines) 

To classify a concave polygon (e.g. a concave star-shaped polygon), compose it out of adjacent disjoint convex shapes and an OR function. 3-layer network can do this.

3-layer network can classify any number of disjoint convex or concave shapes. Use 2-layer networks to classify each convex region to any level of granularity required (just add more lines, and more disjoint areas), and an OR gate. 

Number of neurons in a layer: The same can be said for number of neurons as well. The number of neurons in the input layer and the output layer is obvious to decide but for the hidden layers, it can require some thought. In my work, I found that decreasing size of the layers toward the output layer works better. The rule of thumb says that the number of neurons are generally set between input size and the output size.


```python
import numpy as np
```


```python
# Generate Data
npts=50
data1 = np.random.multivariate_normal( [0,0], [[.01, 0], [0, .01]], npts)
data2 = np.random.multivariate_normal( [1,1], [[.01, 0], [0, .01]], npts)
data3 = np.random.multivariate_normal( [0,1], [[.01, 0], [0, .01]], npts)
data4 = np.random.multivariate_normal( [1,0], [[.01, 0], [0, .01]], npts)

X = np.concatenate((data1, data2, data3, data4))
y = np.concatenate((np.ones((npts*2)),np.zeros((npts*2))))
```


```python
import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))
plt.scatter(X[:2*npts,0], X[:2*npts,1])
plt.scatter(X[2*npts:,0], X[2*npts:,1])
plt.title('XOR dataset',fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
plt.grid('on')
plt.show()
```


![png](output_4_0.png)



```python
print(X.shape)
print(y.shape)
```

    (200, 2)
    (200,)



```python
import keras
from keras import models
from keras import layers
#X1=X.reshape((200*2))
#y1=y.reshape((200))

model = models.Sequential()
model.add(layers.Dense(4, activation='sigmoid', input_shape=(npts*4,)))
model.add(layers.Dense(1, activation='sigmoid'))
model.summary()
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history = model.fit(X, 
                    y, 
                    epochs=20)
print (model.predict(X1))


```

    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    dense_3 (Dense)              (None, 4)                 804       
    _________________________________________________________________
    dense_4 (Dense)              (None, 1)                 5         
    =================================================================
    Total params: 809.0
    Trainable params: 809
    Non-trainable params: 0.0
    _________________________________________________________________



    ---------------------------------------------------------------------------

    ValueError                                Traceback (most recent call last)

    <ipython-input-21-8756e54b327c> in <module>()
         12 history = model.fit(X, 
         13                     y,
    ---> 14                     epochs=20)
         15 print (model.predict(X1))
         16 


    /apps/anaconda/4.3.1/3/lib/python3.6/site-packages/keras/models.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)
        843                               class_weight=class_weight,
        844                               sample_weight=sample_weight,
    --> 845                               initial_epoch=initial_epoch)
        846 
        847     def evaluate(self, x, y, batch_size=32, verbose=1,


    /apps/anaconda/4.3.1/3/lib/python3.6/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)
       1403             class_weight=class_weight,
       1404             check_batch_axis=False,
    -> 1405             batch_size=batch_size)
       1406         # prepare validation data
       1407         if validation_data:


    /apps/anaconda/4.3.1/3/lib/python3.6/site-packages/keras/engine/training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)
       1293                                     self._feed_input_shapes,
       1294                                     check_batch_axis=False,
    -> 1295                                     exception_prefix='model input')
       1296         y = _standardize_input_data(y, self._feed_output_names,
       1297                                     output_shapes,


    /apps/anaconda/4.3.1/3/lib/python3.6/site-packages/keras/engine/training.py in _standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
        131                             ' to have shape ' + str(shapes[i]) +
        132                             ' but got array with shape ' +
    --> 133                             str(array.shape))
        134     return arrays
        135 


    ValueError: Error when checking model input: expected dense_3_input to have shape (None, 200) but got array with shape (200, 2)



```python


history_dict = history.history
history_dict.keys()

import matplotlib.pyplot as plt

plt.figure(figsize=(20,10))

plt.subplot(121)
loss_values = history_dict['loss']
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, 'bo', label='Training loss')
plt.title('Training loss',fontsize=20)
plt.xlabel('Epochs',fontsize=20)
plt.ylabel('Loss',fontsize=20)
plt.legend(fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)

plt.subplot(122)
acc_values = history_dict['acc']
epochs = range(1, len(acc_values) + 1)
plt.plot(epochs, acc_values, 'bo', label='Training acc')
plt.title('Training accuracy',fontsize=20)
plt.xlabel('Epochs',fontsize=20)
plt.ylabel('Accuracy',fontsize=20)
plt.legend(fontsize=20)
plt.xticks(fontsize=20)
plt.yticks(fontsize=20)
plt.show()
```


```python

```
