{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification hierarchy with a minimum set of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "generator = check_random_state(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a few functions\n",
    "def make_two_3d_circles(n_samples=10, r_out=1, r_in=0.7, noise=0.05):\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    # Make data\n",
    "    u_out = np.random.uniform(0, 2 * np.pi, n_samples) \n",
    "    v_out = np.random.uniform(0, 2 * np.pi, n_samples)\n",
    "    u_in  = np.random.uniform(0, 2 * np.pi, n_samples) \n",
    "    v_in  = np.random.uniform(0, 2 * np.pi, n_samples)\n",
    "    \n",
    "    x_out = r_out * np.outer(np.cos(u_out), np.sin(v_out)) + generator.normal(scale=noise, size=(n_samples,n_samples))\n",
    "    y_out = r_out * np.outer(np.sin(u_out), np.sin(v_out)) + generator.normal(scale=noise, size=(n_samples,n_samples))\n",
    "    z_out = r_out * np.outer(np.ones(np.size(u_out)), np.cos(v_out)) + generator.normal(scale=noise, size=(n_samples,n_samples))\n",
    "    x_in  = r_in  * np.outer(np.cos(u_in), np.sin(v_in)) + generator.normal(scale=noise, size=(n_samples,n_samples))\n",
    "    y_in  = r_in  * np.outer(np.sin(u_in), np.sin(v_in)) + generator.normal(scale=noise, size=(n_samples,n_samples))\n",
    "    z_in  = r_in  * np.outer(np.ones(np.size(u_in)), np.cos(v_in)) + generator.normal(scale=noise, size=(n_samples,n_samples))\n",
    "\n",
    "    # Plot the surface\n",
    "    ax.scatter(x_in,  y_in,  z_in,  alpha=0.4 , color='b', s=200)\n",
    "    ax.scatter(x_out, y_out, z_out, alpha=0.4 , color='r' , s=200)\n",
    "\n",
    "    for t in ax.xaxis.get_major_ticks(): t.label.set_fontsize(20)\n",
    "    for t in ax.yaxis.get_major_ticks(): t.label.set_fontsize(20)\n",
    "    for t in ax.zaxis.get_major_ticks(): t.label.set_fontsize(20)\n",
    "    #plt.xlabel('distance from the origin', fontsize=20)\n",
    "    #plt.ylabel('distance from the origin', fontsize=20)\n",
    "    #plt.zlabel('distance from the origin', fontsize=20)\n",
    "    ax.set_xlabel('\\n\\ndistance from the origin', fontsize=20)\n",
    "    ax.set_ylabel('\\n\\ndistance from the origin', fontsize=20)\n",
    "    ax.set_zlabel('\\n\\ndistance from the origin', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "    X = np.vstack((np.append(x_out, x_in),\n",
    "                   np.append(y_out, y_in),\n",
    "                   np.append(z_out, z_in))).T\n",
    "    y = np.hstack([np.zeros(int(len(X)/2), dtype=np.intp),\n",
    "                   np.ones (int(len(X)/2), dtype=np.intp)])\n",
    "    return(X,y)\n",
    "\n",
    "def plot_data_2d(X, y, title_str):\n",
    "    \n",
    "    amin, bmin = X.min(axis=0) - 0.1\n",
    "    amax, bmax = X.max(axis=0) + 0.1\n",
    "    hticks = np.linspace(amin, amax, 101)\n",
    "    vticks = np.linspace(bmin, bmax, 101)\n",
    "    \n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.scatter(X[y==0,0], X[y==0,1],c='r', s=200, alpha=0.4)\n",
    "    plt.scatter(X[y==1,0], X[y==1,1],c='b', s=200, alpha=0.4)\n",
    "    plt.title(title_str,fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xlim(amin, amax)\n",
    "    plt.ylim(bmin, bmax)\n",
    "    plt.grid('on')\n",
    "\n",
    "def plot_data_1d(X, y, title_str):\n",
    "\n",
    "    plt.plot(X[y==1],'ob', markersize=12, alpha=0.4)\n",
    "    plt.plot(X[y==0],'or', markersize=12, alpha=0.4)\n",
    "    plt.title(title_str,fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.grid('on')\n",
    "\n",
    "def plot_data_1d_2nd_look(X, y, title_str):\n",
    "    \n",
    "    plt.plot(X[y==1],np.ones(X[y==1].shape),'ob', markersize=12, alpha=0.1)\n",
    "    plt.plot(X[y==0],np.zeros(X[y==0].shape),'or', markersize=12, alpha=0.1)\n",
    "    plt.title(title_str,fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.grid('on')\n",
    "\n",
    "    \n",
    "def plot_loss_acc(loss_values, acc_values, titles, legends):\n",
    "    \n",
    "    plt.subplot(121)\n",
    "    epochs = range(1, len(loss_values) + 1)\n",
    "    plt.plot(epochs, loss_values, 'o', label=titles[0])\n",
    "    plt.title(titles[0],fontsize=20)\n",
    "    plt.xlabel('Epoch',fontsize=20)\n",
    "    plt.ylabel('Loss',fontsize=20)\n",
    "    plt.legend(legends,fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    epochs = range(1, len(acc_values) + 1)\n",
    "    plt.plot(epochs, acc_values, 'o', label=titles[1])\n",
    "    plt.title(titles[1],fontsize=20)\n",
    "    plt.xlabel('Epoch',fontsize=20)\n",
    "    plt.ylabel('Accuracy',fontsize=20)\n",
    "    plt.legend(legends,fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3d, y_3d = make_two_3d_circles(n_samples=15, r_out=1, r_in=0.5, noise=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_3d.shape)\n",
    "print(y_3d.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#training constants\n",
    "epochs_num=500\n",
    "batch_size_num=32\n",
    "verbose_num=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', input_shape=(3,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_2_1 = model.fit(X_3d, y_3d, epochs=epochs_num, \n",
    "                        batch_size=batch_size_num, verbose=verbose_num).history\n",
    "#model_2_1 = model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4, activation='relu', input_shape=(3,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_4_1 = model.fit(X_3d, y_3d, epochs=epochs_num, \n",
    "                        batch_size=batch_size_num, verbose=verbose_num).history\n",
    "#model_4_1 = model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(6, activation='relu', input_shape=(3,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_6_1 = model.fit(X_3d, y_3d, epochs=epochs_num, \n",
    "                        batch_size=batch_size_num, verbose=verbose_num).history\n",
    "#model_6_1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_loss_acc(history_2_1['loss'], history_2_1['acc'],\n",
    "              ['Training loss','Training accuracy'],['2_1','4_1','6_1'])\n",
    "plot_loss_acc(history_4_1['loss'], history_4_1['acc'],\n",
    "              ['Training loss','Training accuracy'],['2_1','4_1','6_1'])\n",
    "plot_loss_acc(history_6_1['loss'], history_6_1['acc'],\n",
    "              ['Training loss','Training accuracy'],['2_1','4_1','6_1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2d = PCA(n_components=2).fit_transform(X_3d)\n",
    "\n",
    "y_2d = np.hstack([np.zeros(int(len(X_2d)/2), dtype=np.intp),\n",
    "                  np.ones (int(len(X_2d)/2), dtype=np.intp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_2d(X_2d, y_2d,'2-d projection via PCA')\n",
    "plt.ylabel('distance from the origin',fontsize=20)\n",
    "plt.xlabel('distance from the origin',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', input_shape=(2,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_2_1 = model.fit(X_2d, y_2d, epochs=epochs_num, \n",
    "                        batch_size=batch_size_num, verbose=verbose_num).history\n",
    "#model_2_1 = model\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4, activation='relu', input_shape=(2,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_4_1 = model.fit(X_2d, y_2d, epochs=epochs_num, \n",
    "                        batch_size=batch_size_num, verbose=verbose_num).history\n",
    "#model_4_1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_loss_acc(history_2_1['loss'], history_2_1['acc'],\n",
    "              ['Training loss','Training accuracy'],['2_1','4_1'])\n",
    "plot_loss_acc(history_4_1['loss'], history_4_1['acc'],\n",
    "              ['Training loss','Training accuracy'],['2_1','4_1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_1d = PCA(n_components=1).fit_transform(X_3d)\n",
    "y_1d = np.hstack([np.zeros(int(len(X_1d)/2), dtype=np.intp),\n",
    "                  np.ones (int(len(X_1d)/2), dtype=np.intp)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(121)\n",
    "plot_data_1d(X_1d, y_1d,'1-d projection via PCA')\n",
    "plt.ylabel('distance from the origin',fontsize=20)\n",
    "plt.xlabel('point number',fontsize=20)\n",
    "\n",
    "plt.subplot(122)\n",
    "plot_data_1d_2nd_look(X_1d, y_1d,'1-d projection via PCA')\n",
    "plt.ylabel('label',fontsize=20)\n",
    "plt.xlabel('distance from the origin',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs_num=800\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(2, activation='relu', input_shape=(1,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history_2_1 = model.fit(X_1d, y_1d, epochs=epochs_num, \n",
    "                        batch_size=batch_size_num, verbose=verbose_num).history\n",
    "#model_2_1 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plot_loss_acc(history_2_1['loss'], history_2_1['acc'],\n",
    "              ['Training loss','Training accuracy'],['2_1','4_1','6_1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
